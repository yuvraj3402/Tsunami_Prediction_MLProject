{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"tsunami\\artifact\\data_ingestion\\2024-02-20-15-35-51\\train\\tsunami.csv\")\n",
    "features=[\"ID\",\"YEAR\",\"DAY\",\"HOUR\",\"LOCATION_NAME\",\"MINUTE\",\"LATITUDE\",\"LONGITUDE\",\"DAMAGE_TOTAL_DESCRIPTION\",\"HOUSES_TOTAL_DESCRIPTION\",\"DEATHS_TOTAL_DESCRIPTION\",\"URL\",\"COMMENTS\"]\n",
    "df=df.drop(features,axis=1)\n",
    "df=df[df[\"CAUSE\"].str.contains(\"Unknown\")==False]\n",
    "df[\"MONTH\"]=df[\"MONTH\"].map({1.0:\"January\", 2.0:\"February\",3.0: \"March\",4.0: \"April\", 5.0:\"May\", 6.0:\"June\",7.0: \"July\", 8.0:\"August\",9.0: \"September\",10.0: \"October\",11.0: \"November\",12.0: \"December\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numerical_columns=[\"EQ_MAGNITUDE\",\"EQ_DEPTH\",\"TS_INTENSITY\"]\n",
    "cat_columns=[\"MONTH\",\"COUNTRY\",\"REGION\",\"CAUSE\"]\n",
    "\n",
    "num_pipeline=Pipeline(steps=[\n",
    "                ('impute',SimpleImputer(strategy=\"median\")),\n",
    "                ('StandardScalar',StandardScaler())\n",
    "            ])\n",
    "            \n",
    "            \n",
    "\n",
    "cat_pipeline=Pipeline(steps=[\n",
    "                ('imputer',SimpleImputer(strategy=\"most_frequent\")),\n",
    "                ('OneHotEncoder',OneHotEncoder()),\n",
    "                ('scaler', StandardScaler(with_mean=False))\n",
    "            ])\n",
    "            \n",
    "\n",
    "Preprocessing=ColumnTransformer([\n",
    "                ('num_pipeline',num_pipeline,numerical_columns),\n",
    "                ('cat_pipeline',cat_pipeline,cat_columns)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"EVENT_VALIDITY\",axis=1)\n",
    "y=df[\"EVENT_VALIDITY\"]\n",
    "x1=Preprocessing.fit_transform(X=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "\n",
    "def save_object(file_path:str,obj):\n",
    "    dir_path = os.path.dirname(file_path)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    with open(file_path, \"wb\") as file_obj:\n",
    "        dill.dump(obj, file_obj)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=trans_config.preprocessed_object_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(file_path,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelTrainerArtifact(is_trained=True, trained_model_file_path='c:\\\\Users\\\\Admin\\\\OneDrive\\\\Desktop\\\\Tsunami_Git\\\\Tsunami_Prediction_Pipeline\\\\tsunami\\\\artifact\\\\model_trainer\\\\2024-02-21-13-53-52\\\\trained_model\\\\model.pkl', model_accuracy=0.9276534983341266)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsunami.components.data_ingestion import DataIngestion\n",
    "from tsunami.components.data_validation import DataValidation\n",
    "from tsunami.components.data_transformation import DataTransformation\n",
    "from tsunami.components.model_trainer import ModelTrainer\n",
    "from tsunami.config.configuration import configuration\n",
    "config=configuration()\n",
    "\n",
    "trans_config=config.get_data_transformation_config()\n",
    "\n",
    "ing_obj=DataIngestion(config.get_data_ingestion_config())\n",
    "inj_art=ing_obj.initiate_data_ingestion()\n",
    "\n",
    "\n",
    "val_obj=DataValidation(config.get_data_validation_config(),\n",
    "                       inj_art)\n",
    "\n",
    "val_art=val_obj.initiate_data_validation()\n",
    "\n",
    "\n",
    "trans_obj=DataTransformation(inj_art,\n",
    "                             val_art,\n",
    "                             trans_config)\n",
    "trans_art=trans_obj.initiate_data_transformation()\n",
    "\n",
    "model_config=config.get_mode_trainer_config()\n",
    "\n",
    "model_trainer_obj=ModelTrainer(data_transformation_artifact=trans_art,\n",
    "                               model_trainer_config=model_config)\n",
    "\n",
    "model_trainer_obj.initiate_model_trainer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_data(file_path):\n",
    "    df=pd.read_csv(file_path)\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "def load_object(file_path:str):\n",
    "      with open(file_path, \"rb\") as file_obj:\n",
    "           return dill.load(file_obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=trans_art.transformed_train_file_path\n",
    "y=trans_art.target_feature_file_path\n",
    "preproce=load_object(trans_art.preprocessed_object_file_path)\n",
    "x=load_object(file_path=x)\n",
    "y=load_data(file_path=y)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1=RandomForestClassifier(n_estimators=100, max_depth=13)\n",
    "model1=model1.fit(X=x,y=y)\n",
    "predict=model1.predict(X=x)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true=y,y_pred=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=r\"C:\\Users\\Admin\\OneDrive\\Desktop\\Tsunami_Git\\Tsunami_Prediction_Pipeline\\tsunami\\artifact\\data_transformation\\2024-02-20-15-50-23\\transformed_data\\train\\tsunami.npz\"\n",
    "ytrain=r\"tsunami\\artifact\\data_transformation\\2024-02-20-15-50-23\\transformed_data\\target_feature\\target_feature.csv\"\n",
    "model_config=r\"C:\\Users\\Admin\\OneDrive\\Desktop\\Tsunami_Git\\Tsunami_Prediction_Pipeline\\config\\model.yaml\"\n",
    "from tsunami.utils import load_data,load_object\n",
    "xf=load_object(file_path=xtrain)\n",
    "yf=load_data(file_path=ytrain)\n",
    "from tsunami.entity.model_factory import evaluate_regression_model\n",
    "from tsunami.entity.model_factory import ModelFactory\n",
    "model_fac=ModelFactory(model_config_path=model_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fac.get_best_model(x=xf,y=yf,base_accuracy=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf1=yf.values.ravel() \n",
    "\"if using grid search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1=RandomForestClassifier(n_estimators=130, max_depth=20)\n",
    "model1=model1.fit(xf,yf1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"n_estimators\": [130],\n",
    "\"max_depth\": [20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(model1,params,cv=2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf1=yf.values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(xf,yf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=[model1]\n",
    "type(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_regression_model(model_list=m1, X_train=xf, y_train=yf1, base_accuracy=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
